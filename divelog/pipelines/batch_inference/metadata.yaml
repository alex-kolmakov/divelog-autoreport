blocks:
- all_upstream_blocks_executed: true
  color: null
  configuration:
    global_data_product:
      uuid: adverse_condition_labelling_model
  downstream_blocks:
  - generate_reports
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: train_model
  retry_config: null
  status: executed
  timeout: null
  type: global_data_product
  upstream_blocks: []
  uuid: train_model
- all_upstream_blocks_executed: true
  color: null
  configuration:
    global_data_product:
      uuid: dive_data
  downstream_blocks:
  - generate_reports
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: load_data
  retry_config: null
  status: executed
  timeout: null
  type: global_data_product
  upstream_blocks: []
  uuid: load_data
- all_upstream_blocks_executed: true
  color: null
  configuration: {}
  downstream_blocks:
  - notion_export
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: generate_reports
  retry_config: null
  status: updated
  timeout: null
  type: transformer
  upstream_blocks:
  - load_data
  - train_model
  uuid: generate_reports
- all_upstream_blocks_executed: false
  color: teal
  configuration:
    file_source:
      path: custom/notion_export.py
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: notion_export
  retry_config: null
  status: updated
  timeout: null
  type: custom
  upstream_blocks:
  - generate_reports
  uuid: notion_export
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals: []
created_at: '2024-06-08 11:25:09.089898+00:00'
data_integration: null
description: Uses Mlflow registry to pull weights of the model and then does batch
  inference on all of the dive. If notion details provided - uploads the data to the
  notion page.
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: batch_inference
notification_config: {}
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
tags: []
type: python
uuid: batch_inference
variables_dir: /home/src/mage_data/divelog
widgets: []
